{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d37e4-a50a-49c9-b8c1-f887ebf26d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#spliting data frames\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Regular expressions\n",
    "import re\n",
    "\n",
    "# Unidecoder\n",
    "import unicodedata\n",
    "\n",
    "# Timestamp / time measurment\n",
    "import time\n",
    "\n",
    "# Simpletransformers classifier\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "# Label encode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Model performance scores\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# PyTorch: enable GPU access\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffec8fe-260a-448c-812f-6202e72153ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use GPU {}:'.format(torch.cuda.current_device()), torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7fcc08-345c-40ae-b0f9-469d4b77e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define required functions\n",
    "\n",
    "# Define additional model performance scores (F1)\n",
    "def f1_multiclass_macro(labels, preds):\n",
    "    return f1_score(labels, preds, average='macro')\n",
    "def f1_multiclass_micro(labels, preds):\n",
    "    return f1_score(labels, preds, average='micro')\n",
    "def f1_multiclass_weighted(labels, preds):\n",
    "    return f1_score(labels, preds, average='weighted')\n",
    "def f1_class(labels, preds):\n",
    "    return f1_score(labels, preds, average=None)\n",
    "def precision(labels, preds):\n",
    "    return precision_score(labels, preds, average='macro')\n",
    "def recall(labels, preds):\n",
    "    return recall_score(labels, preds, average='macro')\n",
    "\n",
    "# Define text pre-processing functions\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "def remove_non_ascii(text):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "def strip_underscores(text):\n",
    "    return re.sub(r'_+', ' ', text)\n",
    "def remove_multiple_spaces(text):\n",
    "    return re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "# Merge text pre-processing functions\n",
    "def denoise_text(text):\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_non_ascii(text)\n",
    "    text = strip_underscores(text)\n",
    "    text = remove_multiple_spaces(text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf500cbf-d36f-4a47-b38d-e475a61211d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data\n",
    "main=pd.read_excel(r'XXXX.xlsx', index_col=None, engine='openpyxl').rename(columns={\"label\": \"labels_orig\",\n",
    "\"document\":\"text\"})\n",
    "main.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c6e2a-d965-406a-ba94-07b5c0988f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, valid, test = np.array_split(main, 3)\n",
    "train, test = train_test_split(main, test_size=0.3)\n",
    "train.info()\n",
    "#valid.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52accc45-7dd2-411a-bf22-da5c4a1bfa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the text\n",
    "train['text'] = train['text'].astype(str).apply(denoise_text)\n",
    "#valid['text'] = valid['text'].astype(str).apply(denoise_text)\n",
    "test['text'] = test['text'].astype(str).apply(denoise_text)\n",
    "\n",
    "# Load the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the labels\n",
    "train['labels'] = label_encoder.fit_transform(train.labels_orig)\n",
    "#valid['labels'] = label_encoder.fit_transform(valid.labels_orig)\n",
    "test['labels'] = label_encoder.fit_transform(test.labels_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0452ea05-8426-4c2b-961b-5aa1b126cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4561a65-2093-4d6e-884b-67c4c071aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of categories\n",
    "print(round(train.labels.value_counts(normalize=True),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f443f0-40ac-46f4-8cd6-e6bacbf3caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weights\n",
    "train_classes = train.labels\n",
    "print(train_classes)\n",
    "weights = compute_class_weight(class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_classes),\n",
    "                                        y = train_classes)\n",
    "weights = [*weights]\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7810316-54d1-426e-b1a9-cd1b00d57210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ClassificationModel\n",
    "model = ClassificationModel('roberta', 'roberta-large', \n",
    "                            num_labels = 21, weight = weights, use_cuda= False,\n",
    "                            args={'reprocess_input_data': True, \n",
    "                                  'overwrite_output_dir': False,\n",
    "                                  'output_dir': 'models/new_model/',\n",
    "                                  'best_model_dir': 'models/new_model/best_model/',\n",
    "                                  # Hyperparameters\n",
    "                                  'train_batch_size': 6,\n",
    "                                  'num_train_epochs': 3, \n",
    "                                  'learning_rate': 1e-5,\n",
    "                                  # Text processing\n",
    "                                  'max_seq_length': 256,\n",
    "                                  'sliding_window': True,\n",
    "                                  'stride': 0.6,\n",
    "                                  'do_lower_case': False,\n",
    "                                  # Evaluation\n",
    "                                  'evaluate_during_training': True,\n",
    "                                  'evaluate_during_training_verbose': True,\n",
    "                                  'evaluate_during_training_steps': -1,\n",
    "                                  # Saving\n",
    "                                  'save_model_every_epoch': True,\n",
    "                                  'save_eval_checkpoints': True,\n",
    "                                  'weight_decay': 0\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064334c-7207-475f-a95e-b97e632dae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "model.train_model(train, eval_df = test,\n",
    "                  f1_macro = f1_multiclass_macro, \n",
    "                  f1_micro = f1_multiclass_micro, \n",
    "                  f1_weighted = f1_multiclass_weighted, \n",
    "                  acc = accuracy_score, \n",
    "                  f1_class = f1_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce2d418-ab0d-4751-b6d0-da54a250d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Evaluate the classifier performance on the validation data\n",
    "result, model_outputs, wrong_predictions = model.eval_model(test, \n",
    "                                                            f1_macro = f1_multiclass_macro,\n",
    "                                                            precision = precision, \n",
    "                                                            recall = recall,\n",
    "                                                            acc = accuracy_score,\n",
    "                                                            f1_micro = f1_multiclass_micro, \n",
    "                                                            f1_weighted = f1_multiclass_weighted, \n",
    "                                                            f1_class = f1_class)\n",
    "\n",
    "print('Test Results on Validation Dataset')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb3972-9a39-4da0-859a-fe5cd1f8e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('/RussiaBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c271d97-9662-4b35-a4be-1204df95d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame.from_dict(result) # change it to pandas\n",
    "df_result # view\n",
    "df_result[[\"precision\",\"recall\", \"f1_macro\", \"f1_weighted\"]].mean() # get the means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
